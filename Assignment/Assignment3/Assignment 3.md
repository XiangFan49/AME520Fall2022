# AME520Fall2022

### For your first exercise with optitrack; create a mocap recording, 1-2 minutes long, in a bvh file (https://research.cs.wisc.edu/graphics/Courses/cs-838-1999/Jeff/BVH.html) as a deliverable for this assignment. We will be learning how to integrate bvh into 3D environments in the next couple of classes.
* https://github.com/XiangFan49/AME520Fall2022/blob/main/Assignment/Assignment3/Mocap%20Recording.bvh

### Consider the 1-2 mins of movement you are going to capture carefully; its qualities e.g., tempo, range, in space, weight, volume, etc] and other physical properties. As well, consider its function; reaching, running, turning [to see something/someone?] architecture for something /someone else? These are different kinds of questions that may or may not be linked to a meaning you are looking to convey in your final project. Please: Write down your movement ‘score’ [descriptive text and/or image is fine] for 1 -2 mins, including your considerations of above Create the capture recording in the Optitrack system Reflect on what you have made, and revise your score accordingly.
* The final project of my AME520 course is presented as part of my applied project, which will involve the use of optitrack motion capture. During the project, participants should be able to observe representations of their own movements in real-time through VR glasses. At the same time, they feel their own embodied cognition through the movement of their own limbs. Simply put, participants will wear motion capture clothing to experience the digital scene in the VR environment in the physical space of optitrack motion capture at the same time and perceive their own embodied and disembodied cognition simultaneously in the process of interacting with the environment. 
In this process, the primary scene interaction method will be walking or running in a street because more complex interaction methods will involve more complex technical elements, and the simple walking action should already be able to complete the design purpose, that is, to make participants perceive the difference between digital and physical space through motion.
A flawed part of the existing design may be that participants must wear motion-capture clothing to experience the project. This both raises the bar for participants and largely limits the ways in which participants can act. While the reason for the deficiency is because of the accessibility of the existing technology, the way the project would proceed might be different if an interactive responsive space with sensors were available.
